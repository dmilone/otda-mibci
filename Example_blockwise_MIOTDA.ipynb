{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example block-wise adaptation using FOTDA and BOTDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import unravel_index\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import ot\n",
    "import scipy.io\n",
    "import mne          \n",
    "from mne.decoding import CSP\n",
    "mne.set_log_level(verbose='warning') #to avoid info at terminal\n",
    "import matplotlib.pyplot as pl\n",
    "from random import seed\n",
    "seed(30)\n",
    "from MIOTDAfunctions import*\n",
    "\n",
    "# get the functions from RPA package\n",
    "import rpa.transfer_learning as TL\n",
    "# pyriemann import\n",
    "from pyriemann.classification import MDM\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.utils.base import invsqrtm\n",
    "import timeit\n",
    "\n",
    "#ignore warning \n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_acc=[]\n",
    "results_all=[]\n",
    "results_all_inv=[]\n",
    "\n",
    "rango_cl = [0.1, 0.5, 1, 2, 5, 10, 20]\n",
    "rango_e = [0.1, 0.5, 1, 2, 5, 10, 20]\n",
    "metrica = 'sqeuclidean'\n",
    "outerkfold = 10 # for faster online computation select a lower value\n",
    "innerkfold = dict(nfold=10, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and filter data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName = 'Data/DataSession1_S9.mat'\n",
    "s = scipy.io.loadmat(fName)\n",
    "\n",
    "Data_S1=s[\"X\"]\n",
    "Labels_S1=s[\"y\"]\n",
    "Labels_S1=np.squeeze(Labels_S1)\n",
    "\n",
    "#filterting with mne\n",
    "[nt, nc, ns]=np.shape(Data_S1)\n",
    "Data_S1=np.reshape(Data_S1, [nt, nc*ns])\n",
    "Data_S1=mne.filter.filter_data(Data_S1, 128, 8, 30)\n",
    "Data_S1=np.reshape(Data_S1, [nt,nc,ns])\n",
    "\n",
    "fName = 'Data/DataSession2_S9.mat'\n",
    "s2 = scipy.io.loadmat(fName)\n",
    "\n",
    "Data_S2=s2[\"X\"]\n",
    "Labels_S2=s2[\"y\"]\n",
    "Labels_S2=np.squeeze(Labels_S2)\n",
    "\n",
    "#filterting with mne\n",
    "[nt, nc, ns]=np.shape(Data_S2)\n",
    "Data_S2=np.reshape(Data_S2, [nt, nc*ns])\n",
    "Data_S2=mne.filter.filter_data(Data_S2, 128, 8, 30)\n",
    "Data_S2=np.reshape(Data_S2, [nt,nc,ns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn CSP+LDA from source data (Data_S1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr = Data_S1\n",
    "Ytr = Labels_S1\n",
    "csp = CSP(n_components=6, reg='empirical', log=True, norm_trace=False, cov_est='epoch')\n",
    "#learn csp filters\n",
    "Gtr = csp.fit_transform(Xtr, Ytr)\n",
    "#learn lda\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(Gtr,Ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for each run of 20 trials each learn and apply the transport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running testing RUN=0\n",
      "ACC\n",
      "{'sc': 0.55, 'sr': 0.55, 'rpa': 0.75, 'ea': 0.7, 'fotda_s': 0.75, 'fotda_l1l2': 0.65, 'botda_s': 0.9, 'botda_l1l2': 0.9}\n",
      "CT\n",
      "{'sr': 0.343, 'rpa': 1.892, 'eu': 0.407, 'fotda_s': 0.004, 'fotda_l1l2': 0.052, 'botda_s': 0.003, 'botda_l1l2': 0.03}\n",
      "Running testing RUN=1\n",
      "ACC\n",
      "{'sc': 0.7, 'sr': 0.8, 'rpa': 0.8, 'ea': 0.85, 'fotda_s': 0.8, 'fotda_l1l2': 0.8, 'botda_s': 0.75, 'botda_l1l2': 0.85}\n",
      "CT\n",
      "{'sr': 0.324, 'rpa': 3.249, 'eu': 0.553, 'fotda_s': 0.004, 'fotda_l1l2': 0.091, 'botda_s': 0.004, 'botda_l1l2': 0.047}\n",
      "Running testing RUN=2\n",
      "ACC\n",
      "{'sc': 0.65, 'sr': 0.75, 'rpa': 0.8, 'ea': 0.7, 'fotda_s': 0.75, 'fotda_l1l2': 0.8, 'botda_s': 0.8, 'botda_l1l2': 0.8}\n",
      "CT\n",
      "{'sr': 0.358, 'rpa': 3.038, 'eu': 0.596, 'fotda_s': 0.004, 'fotda_l1l2': 0.073, 'botda_s': 0.004, 'botda_l1l2': 0.056}\n",
      "Running testing RUN=3\n",
      "ACC\n",
      "{'sc': 0.75, 'sr': 0.8, 'rpa': 0.8, 'ea': 0.8, 'fotda_s': 0.8, 'fotda_l1l2': 0.8, 'botda_s': 0.8, 'botda_l1l2': 0.8}\n",
      "CT\n",
      "{'sr': 0.362, 'rpa': 3.536, 'eu': 0.652, 'fotda_s': 0.005, 'fotda_l1l2': 0.074, 'botda_s': 0.005, 'botda_l1l2': 0.071}\n",
      "Running testing RUN=4\n",
      "ACC\n",
      "{'sc': 0.95, 'sr': 0.8, 'rpa': 1.0, 'ea': 0.95, 'fotda_s': 0.95, 'fotda_l1l2': 0.95, 'botda_s': 1.0, 'botda_l1l2': 0.95}\n",
      "CT\n",
      "{'sr': 0.447, 'rpa': 3.208, 'eu': 0.689, 'fotda_s': 0.026, 'fotda_l1l2': 0.266, 'botda_s': 0.018, 'botda_l1l2': 0.208}\n",
      "Running testing RUN=5\n",
      "ACC\n",
      "{'sc': 0.7, 'sr': 0.75, 'rpa': 0.65, 'ea': 0.65, 'fotda_s': 0.7, 'fotda_l1l2': 0.7, 'botda_s': 0.65, 'botda_l1l2': 0.65}\n",
      "CT\n",
      "{'sr': 0.358, 'rpa': 2.334, 'eu': 0.647, 'fotda_s': 0.097, 'fotda_l1l2': 0.248, 'botda_s': 0.015, 'botda_l1l2': 0.263}\n",
      "Running testing RUN=6\n"
     ]
    }
   ],
   "source": [
    "for re in range(0,7):\n",
    "    print('Running testing RUN={:1.0f}'.format(re))\n",
    "    #testing run\n",
    "    Xte = Data_S2[0+20*(re+1):20*(re+1)+20]\n",
    "    Yte = Labels_S2[0+20*(re+1):20*(re+1)+20]\n",
    "    #transportation set-prior data\n",
    "    Xval = Data_S2[0:20*re+20]\n",
    "    Yval = Labels_S2[0:20*re+20]\n",
    "    \n",
    "    #feature computation\n",
    "    Gval = csp.transform(Xval)\n",
    "    Gte = csp.transform(Xte)\n",
    "    \n",
    "    #evaluate SC  \n",
    "    acc_sc = lda.score(Gte, Yte)\n",
    "    \n",
    "    # time\n",
    "    start = timeit.default_timer()\n",
    "    #evaluate SR\n",
    "    Xtr2add = Data_S2[0:20*re+20]\n",
    "    Ytr2add=Labels_S2[0:20*re+20]\n",
    "    Xtr2 = np.vstack(((Xtr, Xtr2add)))\n",
    "    Ytr2 = np.hstack(((Ytr, Ytr2add)))\n",
    "        \n",
    "    Ytr2 = Ytr2[len(Ytr2add):]\n",
    "    Xtr2 = Xtr2[len(Ytr2add):]\n",
    "\n",
    "    csp2 = CSP(n_components=6, reg='empirical', log=True, norm_trace=False, cov_est='epoch')\n",
    "    #learn new csp filters\n",
    "    Gtr2 = csp2.fit_transform(Xtr2,Ytr2)\n",
    "    #learn new lda\n",
    "    lda2 = LinearDiscriminantAnalysis()\n",
    "    lda2.fit(Gtr2,Ytr2)\n",
    "\n",
    "    Gte2 = csp2.transform(Xte)\n",
    "    Gval2 = csp2.transform(Xval)\n",
    "    #ldatest\n",
    "    acc_sr = lda2.score(Gte2, Yte)\n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time_sr = stop - start\n",
    "    \n",
    "\n",
    "    M = len(Yval)\n",
    "    \n",
    "    #%% # Sinkhorn Transport\n",
    "    # Subset selection\n",
    "    \n",
    "    lda3 = LinearDiscriminantAnalysis()\n",
    "\n",
    "    G_FOTDAs_, Y_FOTDAs_, regu_FOTDAs_=\\\n",
    "    SelectSubsetTraining_OTDAs(Gtr, Ytr, Gval, Yval, rango_e, lda3, metrica, outerkfold, innerkfold, M)\n",
    "\n",
    "    #time\n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    Gtr_daot=G_FOTDAs_\n",
    "    Ytr_daot=Y_FOTDAs_ \n",
    "    ot_sinkhorn= ot.da.SinkhornTransport(metric=metrica, reg_e=regu_FOTDAs_)\n",
    "    #learn the map\n",
    "    ot_sinkhorn.fit(Xs=Gtr_daot, ys=Ytr_daot, Xt=Gval)\n",
    "    #apply the mapping over source data\n",
    "    transp_Xs_sinkhorn = ot_sinkhorn.transform(Xs=Gtr)\n",
    "\n",
    "    # train a new classifier bases upon the transform source data\n",
    "    lda3.fit(transp_Xs_sinkhorn,Ytr)\n",
    "    # Compute acc\n",
    "    yt_predict_1=lda3.predict(Gte)\n",
    "    acc_fotdas=accuracy_score(Yte, yt_predict_1)\n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time_fs = stop - start  \n",
    "    #%% # Group-Lasso Transport\n",
    "    # Subset selection\n",
    "   \n",
    "    lda3 = LinearDiscriminantAnalysis()\n",
    "\n",
    "    G_FOTDAl1l2_, Y_FOTDAl1l2_, regu_FOTDAl1l2_=\\\n",
    "    SelectSubsetTraining_OTDAl1l2(Gtr, Ytr, Gval, Yval, rango_e, rango_cl, lda3, metrica, outerkfold, innerkfold, M)\n",
    "    #time\n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    Gtr_daot=G_FOTDAl1l2_\n",
    "    Ytr_daot=Y_FOTDAl1l2_\n",
    "    \n",
    "    ot_l1l2 = ot.da.SinkhornL1l2Transport(metric=metrica ,reg_e=regu_FOTDAl1l2_[0], reg_cl=regu_FOTDAl1l2_[1])\n",
    "\n",
    "    ot_l1l2.fit(Xs=Gtr_daot, ys=Ytr_daot, Xt=Gval)\n",
    "\n",
    "    #transport taget samples onto source samples\n",
    "    transp_Xs_l1l2=ot_l1l2.transform(Xs=Gtr)\n",
    "\n",
    "    # train a new classifier bases upon the transform source data\n",
    "    lda3.fit(transp_Xs_l1l2,Ytr)\n",
    "\n",
    "    # Compute acc\n",
    "    yt_predict_2=lda3.predict(Gte)\n",
    "    acc_fotdal1l2=accuracy_score(Yte, yt_predict_2)\n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time_fg = stop - start \n",
    "        \n",
    "    #%% # Backward Sinkhorn Transport\n",
    "    # Subset selection\n",
    "    \n",
    "    G_BOTDAs_, Y_BOTDAs_, regu_BOTDAs_=\\\n",
    "    SelectSubsetTraining_BOTDAs(Gtr, Ytr, Gval, Yval, rango_e, lda, metrica, outerkfold, innerkfold, M)\n",
    "    # time\n",
    "    start = timeit.default_timer()\n",
    "    Gtr_botda=G_BOTDAs_\n",
    "    Ytr_botda=Y_BOTDAs_\n",
    "    \n",
    "    bot_s = ot.da.SinkhornTransport(metric=metrica, reg_e=regu_BOTDAs_)\n",
    "    \n",
    "    \n",
    "    bot_s.fit(Xs=Gval, ys=Yval, Xt=Gtr_botda)\n",
    "    #transport testing samples\n",
    "    transp_Xt_s_backward=bot_s.transform(Xs=Gte)\n",
    "    # Compute accuracy without retraining    \n",
    "    yt_predict_3=lda.predict(transp_Xt_s_backward)\n",
    "    acc_botdas=accuracy_score(Yte, yt_predict_3)\n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time_bs = stop - start\n",
    "    \n",
    "    #%% # Backward Group-Lasso Transport\n",
    "    # Subset selection \n",
    "    G_BOTDAl1l2_, Y_BOTDAl1l2_, regu_BOTDAl1l2_=\\\n",
    "    SelectSubsetTraining_BOTDAl1l2(Gtr, Ytr, Gval, Yval, rango_e, rango_cl, lda, metrica, outerkfold, innerkfold, M)\n",
    "    \n",
    "    #time\n",
    "    start = timeit.default_timer()\n",
    "    Gtr_botda=G_BOTDAl1l2_\n",
    "    Ytr_botda=Y_BOTDAl1l2_\n",
    "    \n",
    "    bot_l1l2 = ot.da.SinkhornL1l2Transport(metric=metrica, reg_e=regu_BOTDAl1l2_[0], reg_cl=regu_BOTDAl1l2_[1])\n",
    "    \n",
    "    bot_l1l2.fit(Xs=Gval, ys=Yval, Xt=Gtr_botda)\n",
    "    #transport testing samples\n",
    "    transp_Xt_l1l2_backward=bot_l1l2.transform(Xs=Gte)\n",
    "    # Compute accuracy without retraining    \n",
    "    yt_predict_4=lda.predict(transp_Xt_l1l2_backward)\n",
    "    acc_botdal1l2=accuracy_score(Yte, yt_predict_4)\n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time_bg = stop - start\n",
    "    \n",
    "    # Riemann\n",
    "    # time\n",
    "    start = timeit.default_timer()\n",
    "    # cov matrix estimation\n",
    "    cov_tr = Covariances().transform(Xtr)\n",
    "    cov_val= Covariances().transform(Xval)\n",
    "    cov_te = Covariances().transform(Xte)\n",
    "        \n",
    "    clf = MDM()\n",
    "    source={'covs':cov_tr, 'labels': Ytr}\n",
    "    target_org_train={'covs':cov_val, 'labels': Yval}\n",
    "    target_org_test={'covs':cov_te, 'labels': Yte}\n",
    "    # re-centered matrices\n",
    "    source_rct, target_rct_train, target_rct_test = TL.RPA_recenter(source, target_org_train, target_org_test)   \n",
    "    # rotate the re-centered-stretched matrices using information from classes\n",
    "    source_rpa, target_rpa_train, target_rpa_test = TL.RPA_rotate(source_rct, target_rct_train, target_rct_test)\n",
    "    # get data\n",
    "    covs_source, y_source = source_rpa['covs'], source_rpa['labels']\n",
    "    covs_target_train, y_target_train = target_rpa_train['covs'], target_rpa_train['labels']\n",
    "    covs_target_test, y_target_test = target_rpa_test['covs'], target_rpa_test['labels']\n",
    "    # append train and validation data\n",
    "    covs_train = np.concatenate([covs_source, covs_target_train])\n",
    "    y_train = np.concatenate([y_source, y_target_train])\n",
    "    # train\n",
    "    clf.fit(covs_train, y_train)\n",
    "    # test\n",
    "    covs_test = covs_target_test\n",
    "    y_test = y_target_test\n",
    "    y_pred = clf.predict(covs_test)\n",
    "    #acc\n",
    "    acc_rpa = accuracy_score(Yte, y_pred)\n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time_rpa = stop - start\n",
    "        \n",
    "    # Euclidean\n",
    "    # time\n",
    "    start = timeit.default_timer()\n",
    "    # Estimate single trial covariance\n",
    "    cov_tr = Covariances().transform(Xtr)\n",
    "    cov_val= Covariances().transform(Xval)\n",
    "    Ctr = cov_tr.mean(0)\n",
    "    Cval = cov_val.mean(0)\n",
    "    # aligment\n",
    "    Xtr_eu = np.asarray([np.dot(invsqrtm(Ctr), epoch) for epoch in Xtr])\n",
    "    Xval_eu = np.asarray([np.dot(invsqrtm(Cval), epoch) for epoch in Xval])\n",
    "    Xte_eu = np.asarray([np.dot(invsqrtm(Cval), epoch) for epoch in Xte])\n",
    "\n",
    "    # append train and validation data\n",
    "    x_train = np.concatenate([Xtr_eu, Xval_eu])\n",
    "    y_train = np.concatenate([Ytr, Yval])\n",
    "\n",
    "    # train new csp+lda\n",
    "    csp2 = CSP(n_components=6, reg='empirical', log=True, norm_trace=False, cov_est='epoch')\n",
    "    # learn csp filters\n",
    "    Gtr2 = csp2.fit_transform(x_train,y_train)\n",
    "    # learn lda\n",
    "    lda2 = LinearDiscriminantAnalysis()\n",
    "\n",
    "    lda2.fit(Gtr2,y_train)\n",
    "    \n",
    "    # test\n",
    "    Gte2=csp2.transform(Xte_eu)  \n",
    "    # acc\n",
    "    acc_eu=lda2.score(Gte2, Yte)\n",
    "    # time\n",
    "    stop = timeit.default_timer()\n",
    "    time_eu = stop - start\n",
    "        \n",
    "    \n",
    "    # print results\n",
    "    # accuracy\n",
    "    acc = {}\n",
    "    acc[\"sc\"] = acc_sc\n",
    "    acc[\"sr\"] = acc_sr\n",
    "    acc[\"rpa\"] = acc_rpa\n",
    "    acc[\"ea\"] = acc_eu\n",
    "    acc[\"fotda_s\"] = acc_fotdas\n",
    "    acc[\"fotda_l1l2\"] = acc_fotdal1l2\n",
    "    acc[\"botda_s\"] = acc_botdas\n",
    "    acc[\"botda_l1l2\"] = acc_botdal1l2\n",
    "    \n",
    "    # computing time\n",
    "    time = {}\n",
    "    time[\"sr\"] = round(time_sr,3)\n",
    "    time[\"rpa\"] = round(time_rpa,3)\n",
    "    time[\"eu\"] = round(time_eu,3)\n",
    "    time[\"fotda_s\"] = round(time_fs,3)\n",
    "    time[\"fotda_l1l2\"] = round(time_fg,3)\n",
    "    time[\"botda_s\"] = round(time_bs,3)\n",
    "    time[\"botda_l1l2\"] = round(time_bg,3)\n",
    "    \n",
    "    print('ACC')\n",
    "    print(acc)\n",
    "    print('CT')\n",
    "    print(time)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting-->for the last testing run  \n",
    "\n",
    "#distribution datasets\n",
    "pl.figure(figsize=(8, 4))\n",
    "\n",
    "pl.subplot(1, 3, 1)\n",
    "pl.scatter(Gtr[Ytr==1, 0], Gtr[Ytr==1, 1], c='orange', marker='o', label='Class 1')\n",
    "pl.scatter(Gtr[Ytr==2, 0], Gtr[Ytr==2, 1], c='indigo', marker='+', label='Class 2')\n",
    "\n",
    "pl.xticks([])\n",
    "pl.yticks([])\n",
    "pl.legend(loc=1)\n",
    "pl.title('Source (training) set')\n",
    "\n",
    "pl.subplot(1, 3, 2)\n",
    "pl.scatter(Gval[Yval==1, 0], Gval[Yval==1, 1], c='orange', marker='o', label='Class 1')\n",
    "pl.scatter(Gval[Yval==2, 0], Gval[Yval==2, 1], c='indigo', marker='+', label='Class 2')\n",
    "\n",
    "pl.xticks([])\n",
    "pl.yticks([])\n",
    "pl.legend(loc=1)\n",
    "pl.title('Transportation set')\n",
    "pl.tight_layout()\n",
    "\n",
    "    \n",
    "pl.subplot(1, 3, 3)\n",
    "pl.scatter(Gte[Yte==1, 0], Gte[Yte==1, 1], c='orange', marker='o', label='Class 1')\n",
    "pl.scatter(Gte[Yte==2, 0], Gte[Yte==2, 1], c='indigo', marker='+', label='Class 2')\n",
    "\n",
    "pl.xticks([])\n",
    "pl.yticks([])\n",
    "pl.legend(loc=1)\n",
    "pl.title('Target (testing) set' )\n",
    "pl.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting original and transported samples for each method\n",
    "pl.figure(figsize=(10, 11))\n",
    "    \n",
    "pl.subplot(2, 2, 1)\n",
    "pl.scatter(Gte[Yte==1, 0], Gte[Yte==1, 1], c='orange', marker='o',\n",
    "           alpha=0.5)\n",
    "pl.scatter(Gte[Yte==2, 0], Gte[Yte==2, 1], c='indigo', marker='o',\n",
    "           alpha=0.5)\n",
    "pl.scatter(transp_Xs_sinkhorn[Ytr==1, 0], transp_Xs_sinkhorn[Ytr==1, 1], c='orange',\n",
    "           marker='+', s=50 )\n",
    "pl.scatter(transp_Xs_sinkhorn[Ytr==2, 0], transp_Xs_sinkhorn[Ytr==2, 1], c='indigo',\n",
    "           marker='+', s=50 )\n",
    "pl.title('Transported source samples\\n FOTDA-S', size=14)\n",
    "pl.xticks([])\n",
    "pl.yticks([])\n",
    "\n",
    "#l1l2\n",
    "pl.subplot(2, 2, 2)\n",
    "pl.scatter(Gte[Yte==1, 0], Gte[Yte==1, 1], c='orange', marker='o',\n",
    "           alpha=0.5)\n",
    "pl.scatter(Gte[Yte==2, 0], Gte[Yte==2, 1], c='indigo', marker='o',\n",
    "           alpha=0.5)\n",
    "pl.scatter(transp_Xs_l1l2[Ytr==1, 0], transp_Xs_l1l2[Ytr==1, 1], c='orange',\n",
    "           marker='+', s=50 )\n",
    "pl.scatter(transp_Xs_l1l2[Ytr==2, 0], transp_Xs_l1l2[Ytr==2, 1], c='indigo',\n",
    "           marker='+', s=50 )\n",
    "pl.title('Transported source samples\\n FOTDA-GL', size=14)\n",
    "pl.xticks([])\n",
    "pl.yticks([])\n",
    "\n",
    "\n",
    "#S-B\n",
    "pl.subplot(2, 2, 3)\n",
    "pl.scatter(Gtr[Ytr==1, 0], Gtr[Ytr==1, 1], c='orange', marker='o',alpha=0.5)\n",
    "pl.scatter(Gtr[Ytr==2, 0], Gtr[Ytr==2, 1], c='indigo', marker='o',alpha=0.5)\n",
    "\n",
    "pl.scatter(transp_Xt_s_backward[Yte==1, 0], transp_Xt_s_backward[Yte==1, 1], c='orange',\n",
    "            marker='+', s=50)\n",
    "pl.scatter(transp_Xt_s_backward[Yte==2, 0], transp_Xt_s_backward[Yte==2, 1], c='indigo',\n",
    "            marker='+', s=0)\n",
    "pl.title('Transported target samples\\n BOTDA-S', size=14)\n",
    "pl.xticks([])\n",
    "pl.yticks([])\n",
    "\n",
    "    \n",
    "#l1l2-B\n",
    "pl.subplot(2, 2, 4)\n",
    "pl.scatter(Gtr[Ytr==1, 0], Gtr[Ytr==1, 1], c='orange', marker='o',alpha=0.5, \n",
    "           Label='Source samples class-1')\n",
    "pl.scatter(Gtr[Ytr==2, 0], Gtr[Ytr==2, 1], c='indigo', marker='o',alpha=0.5,\n",
    "           Label='Source samples class-2')\n",
    "\n",
    "pl.scatter(transp_Xt_l1l2_backward[Yte==1, 0], transp_Xt_l1l2_backward[Yte==1, 1], c='orange',\n",
    "            marker='+', s=50, Label='Transp. Target samples class-1')\n",
    "pl.scatter(transp_Xt_l1l2_backward[Yte==2, 0], transp_Xt_l1l2_backward[Yte==2, 1], c='indigo',\n",
    "            marker='+', s=50, Label='Transp. Target samples class-2')\n",
    "pl.title('Transported target samples\\n BOTDA-GL', size=14)\n",
    "pl.legend(loc=8, ncol=2, mode=\"expand\", bbox_to_anchor=(0, -0.3, 1, 0.65))\n",
    "pl.xticks([])\n",
    "pl.yticks([])\n",
    "pl.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
