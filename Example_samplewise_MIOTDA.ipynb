{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example sample-wise adaptation using OTDA and BOTDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # always need it\n",
    "from numpy import unravel_index\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import ot\n",
    "import scipy.io\n",
    "import mne          \n",
    "from mne.decoding import CSP\n",
    "mne.set_log_level(verbose='warning') #to avoid info at terminal\n",
    "import matplotlib.pyplot as pl\n",
    "from MIOTDAfunctions import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rango_cl=[0.1, 1, 10]\n",
    "rango_e=[0.1, 1, 10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data at filter it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fName = 'Data/DataSession1_S2.mat'\n",
    "s = scipy.io.loadmat(fName)\n",
    "\n",
    "Data_S1=s[\"X\"]\n",
    "Labels_S1=s[\"y\"]\n",
    "Labels_S1=np.squeeze(Labels_S1)\n",
    "\n",
    "#filterting with mne\n",
    "[nt, nc, ns]=np.shape(Data_S1)\n",
    "Data_S1=np.reshape(Data_S1, [nt, nc*ns])\n",
    "Data_S1=mne.filter.filter_data(Data_S1, 128, 8, 30)\n",
    "Data_S1=np.reshape(Data_S1, [nt,nc,ns])\n",
    "\n",
    "fName = 'Data/DataSession2_S2.mat'\n",
    "s2 = scipy.io.loadmat(fName)\n",
    "\n",
    "Data_S2=s2[\"X\"]\n",
    "Labels_S2=s2[\"y\"]\n",
    "Labels_S2=np.squeeze(Labels_S2)\n",
    "\n",
    "#filterting with mne\n",
    "[nt, nc, ns]=np.shape(Data_S2)\n",
    "Data_S2=np.reshape(Data_S2, [nt, nc*ns])\n",
    "Data_S2=mne.filter.filter_data(Data_S2, 128, 8, 30)\n",
    "Data_S2=np.reshape(Data_S2, [nt,nc,ns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learn CSP+LDA from source data (Data_S1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "                           solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr=Data_S1\n",
    "Ytr=Labels_S1\n",
    "csp = CSP(n_components=6, reg='empirical', log=True, norm_trace=False, cov_est='epoch')\n",
    "#learn csp filters\n",
    "Gtr=csp.fit_transform(Xtr,Ytr)\n",
    "#learn lda\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(Gtr,Ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first 20 trials of the new session used as transportation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "Labels_te=Labels_S2[20:]\n",
    "##\n",
    "Xval=Data_S2[0:20]\n",
    "Yval=Labels_S2[0:20]\n",
    "##\n",
    "Gval=csp.transform(Xval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for saving outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_predict_sc=[]\n",
    "yt_predict_sr=[]\n",
    "yt_predict_1=[]\n",
    "yt_predict_2=[]\n",
    "yt_predict_3=[]\n",
    "yt_predict_4=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select subset Gtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset selection re-training path\n",
    "M=20\n",
    "G_FOTDAs_, Y_FOTDAs_, regu_FOTDAs_=\\\n",
    "SelectSubsetTraining_OTDAs(xs=Gtr, ys=Ytr, xv=Gval, yv=Yval, rango_e=rango_e, metrica=\"euclidean\", kfold=20, M=M, trad=True)\n",
    "G_FOTDAl1l2_, Y_FOTDAl1l2_, regu_FOTDAl1l2_=\\\n",
    "    SelectSubsetTraining_OTDAl1l2(xs=Gtr, ys=Ytr, xv=Gval, yv=Yval, rango_e=rango_e, rango_cl=rango_cl, metrica=\"euclidean\", kfold=20, M=M, trad=True)\n",
    "G_BOTDAs_, Y_BOTDAs_, regu_BOTDAs_=\\\n",
    "    SelectSubsetTraining_BOTDAs(xs=Gtr, ys=Ytr, xv=Gval, yv=Yval, rango_e=rango_e, metrica=\"euclidean\", kfold=20, M=M, trad=False)\n",
    "G_BOTDAl1l2_, Y_BOTDAl1l2_, regu_BOTDAl1l2_=\\\n",
    "    SelectSubsetTraining_BOTDAl1l2(xs=Gtr, ys=Ytr, xv=Gval, yv=Yval, rango_e=rango_e, rango_cl=rango_cl, metrica=\"euclidean\", kfold=20, M=M, trad=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for each trial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running testing trial=10\n",
      "Running testing trial=20\n",
      "Running testing trial=30\n",
      "Running testing trial=40\n",
      "Running testing trial=50\n",
      "Running testing trial=60\n",
      "Running testing trial=70\n",
      "Running testing trial=80\n",
      "Running testing trial=90\n",
      "Running testing trial=100\n",
      "Running testing trial=110\n",
      "Running testing trial=120\n",
      "Running testing trial=130\n",
      "Running testing trial=140\n"
     ]
    }
   ],
   "source": [
    "for re in range(1,len(Labels_te)+1):\n",
    "    if np.mod(re,10)==0 : print('Running testing trial={:1.0f}'.format(re))\n",
    "    #testing trial\n",
    "    Xte=Data_S2[20+(re-1):20+(re)]\n",
    "    Xte=Xte.reshape(1, nc, ns)\n",
    "    Yte=Labels_S2[20+(re-1):20+(re)]\n",
    "    \n",
    "    Xval=np.vstack((Xval, Xte))\n",
    "    Yval=np.hstack((Yval, Yte))\n",
    "    \n",
    "    #csp estimation\n",
    "    Gval=csp.transform(Xval)\n",
    "    Gte=csp.transform(Xte)\n",
    "    #feature computation\n",
    "    Gte=csp.transform(Xte)\n",
    "    \n",
    "    #evaluate SC  \n",
    "    yt_predict_sc.append(lda.predict(Gte))\n",
    "\n",
    "    #evaluate SR\n",
    "    Xtr2=np.vstack((Xtr,Xval))\n",
    "    Ytr2=np.hstack((Ytr, Yval))\n",
    "    Xtr2=Xtr2[len(Yval):]\n",
    "    Ytr2=Ytr2[len(Yval):]\n",
    "\n",
    "    csp2 = CSP(n_components=6, reg='empirical', log=True, norm_trace=False, cov_est='epoch')\n",
    "    #learn csp filters\n",
    "    Gtr2=csp2.fit_transform(Xtr2,Ytr2)\n",
    "    #learn lda\n",
    "    lda2 = LinearDiscriminantAnalysis()\n",
    "    lda2.fit(Gtr2,Ytr2)\n",
    "\n",
    "    Gte2=csp2.transform(Xte)\n",
    "\n",
    "    #ldatest\n",
    "    yt_predict_sr.append(lda2.predict(Gte2))\n",
    "\n",
    "    #%% # Sinkhorn Transport\n",
    "    \n",
    "    Gtr_daot=G_FOTDAs_\n",
    "    Ytr_daot=Y_FOTDAs_ \n",
    "    ot_sinkhorn= ot.da.SinkhornTransport(metric=\"euclidean\",reg_e=rango_e[regu_FOTDAs_])\n",
    "    #learn the map\n",
    "    ot_sinkhorn.fit(Xs=Gtr_daot, ys=Ytr_daot, Xt=Gval)\n",
    "    #apply the mapping over source data\n",
    "    transp_Xs_sinkhorn = ot_sinkhorn.transform(Xs=Gtr)\n",
    "\n",
    "    # retraining\n",
    "    lda3 = LinearDiscriminantAnalysis()\n",
    "    lda3.fit(transp_Xs_sinkhorn,Ytr)\n",
    "    # Compute acc\n",
    "    yt_predict_1.append(lda3.predict(Gte))\n",
    "    \n",
    "       \n",
    "    #%% # Group-Lasso Transport\n",
    "  \n",
    "    Gtr_daot=G_FOTDAl1l2_\n",
    "    Ytr_daot=Y_FOTDAl1l2_\n",
    "    \n",
    "    ot_l1l2 = ot.da.SinkhornL1l2Transport(metric=\"euclidean\",reg_e=rango_e[regu_FOTDAl1l2_[0]], reg_cl=rango_cl[regu_FOTDAl1l2_[1]])\n",
    "\n",
    "    ot_l1l2.fit(Xs=Gtr_daot, ys=Ytr_daot, Xt=Gval)\n",
    "\n",
    "    #transport taget samples onto source samples\n",
    "    transp_Xs_l1l2=ot_l1l2.transform(Xs=Gtr)\n",
    "\n",
    "    # retraining\n",
    "    lda3 = LinearDiscriminantAnalysis()\n",
    "    lda3.fit(transp_Xs_l1l2,Ytr)\n",
    "\n",
    "    # Compute acc\n",
    "    yt_predict_2.append(lda3.predict(Gte))\n",
    "    \n",
    "      \n",
    "    #%% # Backward Sinkhorn Transport\n",
    "       \n",
    "    Gtr_botda=G_BOTDAs_\n",
    "    Ytr_botda=Y_BOTDAs_\n",
    "    \n",
    "    bot_s = ot.da.SinkhornTransport(metric=\"euclidean\",reg_e=rango_e[regu_BOTDAs_])\n",
    "    \n",
    "    \n",
    "    bot_s.fit(Xs=Gval, ys=Yval, Xt=Gtr_botda)\n",
    "    #transport testing samples\n",
    "    transp_Xt_s_backward=bot_s.transform(Xs=Gte)\n",
    "    # Compute accuracy one-training    \n",
    "    yt_predict_3.append(lda.predict(transp_Xt_s_backward))\n",
    "   \n",
    "    #%% # Backward Group-Lasso Transport\n",
    "       \n",
    "    Gtr_botda=G_BOTDAl1l2_\n",
    "    Ytr_botda=Y_BOTDAl1l2_\n",
    "    \n",
    "    bot_l1l2 = ot.da.SinkhornL1l2Transport(metric=\"euclidean\",reg_e=rango_e[regu_BOTDAl1l2_[0]], reg_cl=rango_cl[regu_BOTDAl1l2_[1]])\n",
    "        \n",
    "    bot_l1l2.fit(Xs=Gval, ys=Yval, Xt=Gtr_botda)\n",
    "    #transport testing samples\n",
    "    transp_Xt_l1l2_backward=bot_l1l2.transform(Xs=Gte)\n",
    "    # Compute accuracy one-training    \n",
    "    yt_predict_4.append(lda.predict(transp_Xt_l1l2_backward))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sc': 0.7785714285714286, 'sr': 0.8928571428571429, 'fotda_s': 0.7214285714285714, 'fotda_l1l2': 0.7785714285714286, 'botda_s': 0.7, 'botda_l1l2': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy \n",
    "yt_predict_4=np.squeeze(np.asarray(yt_predict_4))\n",
    "yt_predict_3=np.squeeze(np.asarray(yt_predict_3))\n",
    "yt_predict_2=np.squeeze(np.asarray(yt_predict_2))\n",
    "yt_predict_1=np.squeeze(np.asarray(yt_predict_1))\n",
    "yt_predict_sc=np.squeeze(np.asarray(yt_predict_sc))\n",
    "yt_predict_sr=np.squeeze(np.asarray(yt_predict_sr))\n",
    "\n",
    "acc_botdal1l2=accuracy_score(Labels_te, yt_predict_4)\n",
    "acc_botdas=accuracy_score(Labels_te, yt_predict_3)\n",
    "acc_fotdal1l2=accuracy_score(Labels_te, yt_predict_2)\n",
    "acc_fotdas=accuracy_score(Labels_te, yt_predict_1)\n",
    "acc_sc=accuracy_score(Labels_te, yt_predict_sc)\n",
    "acc_sr=accuracy_score(Labels_te, yt_predict_sr)\n",
    "\n",
    "#print accuracy\n",
    "acc={}\n",
    "acc[\"sc\"]=acc_sc\n",
    "acc[\"sr\"]=acc_sr\n",
    "acc[\"fotda_s\"]=acc_fotdas\n",
    "acc[\"fotda_l1l2\"]=acc_fotdal1l2\n",
    "acc[\"botda_s\"]=acc_botdas\n",
    "acc[\"botda_l1l2\"]=acc_botdal1l2\n",
    "    \n",
    "print(acc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
